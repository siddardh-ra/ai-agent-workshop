{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenAI SDK\n",
    "!pip install openai==1.84.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå§Ô∏è Manual AI Agent (No Framework): Weather Checker\n",
    "This notebook demonstrates a simple AI agent without using any frameworks like LangChain.\n",
    "The agent:\n",
    "- Understands if a query is about weather\n",
    "- Extracts the city name using OpenAI\n",
    "- Returns the current weather (simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from openai import OpenAI\n",
    "import os\n",
    "# Set your OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key = \"Enter your API KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_api=\"https://llama-3-1-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1\"\n",
    "model=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=model_api,\n",
    "    api_key=model_key,\n",
    "    http_client=httpx.Client(verify=False)  # DO NOT DO THIS IN PRODUCTION!!!!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy function to simulate weather API\n",
    "def get_weather(city):\n",
    "    return f\"The current weather in {city} is 28¬∞C, partly cloudy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decide if query is about weather\n",
    "def decide_action(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Classifies whether the user query is weather-related.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        'weather' if the LLM says the query is about the weather,\n",
    "        otherwise 'unknown'.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nüîé  Classifying query intent...\")\n",
    "\n",
    "    # Ask the LLM for a one-word verdict.\n",
    "    prompt = f\"Does this query ask about weather? '{user_input}' Answer yes or no.\"\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=5,           # We only need 'yes' or 'no'\n",
    "    )\n",
    "\n",
    "    verdict = response.choices[0].message.content.strip().lower()\n",
    "    print(f\"üß†  LLM verdict: {verdict}\")\n",
    "\n",
    "    return \"weather\" if verdict.startswith(\"yes\") else \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(user_input):\n",
    "    \"\"\"\n",
    "    Full agent flow:\n",
    "    - Detects the type of query (weather or not)\n",
    "    - Extracts city name if needed\n",
    "    - Fetches weather data (simulated)\n",
    "    - Asks LLM to summarize the result\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nüü° Received query: '{user_input}'\")\n",
    "\n",
    "    # Step 1: Let LLM decide if it's a weather-related query\n",
    "    task = decide_action(user_input)\n",
    "    print(f\"üîç LLM classification: '{task}'\")\n",
    "\n",
    "    if task == 'weather':\n",
    "        # Step 2: Ask LLM to extract the city name from the query\n",
    "        city_prompt = f\"From this query, identify the city name only: '{user_input}'\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": city_prompt}]\n",
    "        )\n",
    "        city = response.choices[0].message.content.strip()\n",
    "        print(f\"üèôÔ∏è Extracted city: {city}\")\n",
    "\n",
    "        # Step 3: Simulate fetching weather from an API\n",
    "        weather_data = get_weather(city)\n",
    "        print(f\"üå§Ô∏è Raw weather data: {weather_data}\")\n",
    "\n",
    "        # Step 4: Ask LLM to summarize the raw weather data\n",
    "        summary_prompt = f\"Given this raw weather information from a weather API, rephrase it into a natural and friendly sentence: '{weather_data}'\"\n",
    "        summary_response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": summary_prompt}]\n",
    "        )\n",
    "        final_response = summary_response.choices[0].message.content.strip()\n",
    "        print(f\"‚úÖ Final summarized response: {final_response}\")\n",
    "        return final_response\n",
    "\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Query is not weather-related.\")\n",
    "        return \"Sorry, I can only help with weather-related questions right now.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü° Received query: 'What's the score of the match which happened in Bangalore today?'\n",
      "\n",
      "üîé  Classifying query intent...\n",
      "üß†  LLM verdict: no\n",
      "üîç LLM classification: 'unknown'\n",
      "‚ö†Ô∏è Query is not weather-related.\n",
      "Sorry, I can only help with weather-related questions right now.\n"
     ]
    }
   ],
   "source": [
    "# Test the manual agent\n",
    "query = \"What's the score of the match which happened in Bangalore today?\"\n",
    "print(run_agent(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
